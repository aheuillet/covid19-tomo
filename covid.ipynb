{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Covid-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.utils import to_categorical, Sequence\n",
    "from tensorflow.keras.applications import NASNetLarge\n",
    "from tensorflow.keras.optimizers import Nadam, SGD\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from skimage.io import imread\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.os.makedirs(\"dataset/covid-chestray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone dataset/covid-chestray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 100\n",
    "categories = {}\n",
    "\n",
    "num_classes = len(categories)\n",
    "\n",
    "print(\"Categories: \", categories)\n",
    "print(\"Number of classes: \", num_classes)\n",
    "\n",
    "class COVSequence(Sequence):\n",
    "\n",
    "        def __init__(self, list_path, num_classes, batch_size, shuffle=True, transform=None, data_aug=None, nrows=None):\n",
    "            self.imgpath = imgpath\n",
    "            self.transform = transform\n",
    "            self.data_aug = data_aug\n",
    "            self.views = views\n",
    "            \n",
    "            # defined here to make the code easier to read\n",
    "            pneumonias = [\"COVID-19\", \"SARS\", \"MERS\", \"ARDS\", \"Streptococcus\", \"Pneumocystis\", \"Klebsiella\", \"Chlamydophila\", \"Legionella\"]\n",
    "            \n",
    "            self.pathologies = [\"Pneumonia\",\"Viral Pneumonia\", \"Bacterial Pneumonia\", \"Fungal Pneumonia\", \"No Finding\"] + pneumonias\n",
    "            self.pathologies = sorted(self.pathologies)\n",
    "\n",
    "            mapping = dict()\n",
    "            mapping[\"Pneumonia\"] = pneumonias\n",
    "            mapping[\"Viral Pneumonia\"] = [\"COVID-19\", \"SARS\", \"MERS\"]\n",
    "            mapping[\"Bacterial Pneumonia\"] = [\"Streptococcus\", \"Klebsiella\", \"Chlamydophila\", \"Legionella\"]\n",
    "            mapping[\"Fungal Pneumonia\"] = [\"Pneumocystis\"]\n",
    "            \n",
    "            # Load data\n",
    "            self.csvpath = csvpath\n",
    "            self.csv = pd.read_csv(self.csvpath, nrows=nrows)\n",
    "            self.MAXVAL = 255  # Range [0 255]\n",
    "\n",
    "            # Keep only the frontal views.\n",
    "            #idx_pa = self.csv[\"view\"].isin([\"PA\", \"AP\", \"AP Supine\"])\n",
    "            idx_pa = self.csv[\"view\"].isin(self.views)\n",
    "            self.csv = self.csv[idx_pa]\n",
    "            \n",
    "            self.labels = []\n",
    "            for pathology in self.pathologies:\n",
    "                mask = self.csv[\"finding\"].str.contains(pathology)\n",
    "                if pathology in mapping:\n",
    "                    for syn in mapping[pathology]:\n",
    "                        #print(\"mapping\", syn)\n",
    "                        mask |= self.csv[\"finding\"].str.contains(syn)\n",
    "                self.labels.append(mask.values)\n",
    "            self.labels = np.asarray(self.labels).T\n",
    "            self.labels = self.labels.astype(np.float32)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            batch_paths = self.file_paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "            batch_images = np.empty((self.batch_size, 128, 128, 3))\n",
    "            batch_labels = np.empty((self.batch_size), dtype=int)\n",
    "            for i,p in enumerate(batch_paths):\n",
    "                img, label = self.process_image(p)\n",
    "                batch_images[i,] = img\n",
    "                batch_labels[i] = label\n",
    "            return batch_images, to_categorical(np.array(batch_labels), num_classes=self.num_classes)\n",
    "        \n",
    "        def on_epoch_end(self):\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(self.file_paths)\n",
    "        \n",
    "        def process_image(self, img_path):\n",
    "            label = int(img_path.split(' ')[1])\n",
    "            img = Image.open(img_path.split(' ')[0].strip())\n",
    "            img = img.convert(\"RGB\")\n",
    "            img = img.resize((128, 128))\n",
    "            return np.array(img)/255, label\n",
    "\n",
    "        def get_labels(self):\n",
    "            labels = []\n",
    "            for f in self.file_paths:\n",
    "                labels.append(int(f.split(' ')[1]))\n",
    "            return np.array(labels)\n",
    "        \n",
    "        def get_sample(self, size):\n",
    "            sample_images = np.empty((size, 128, 128, 3))\n",
    "            for i in range(size):\n",
    "                sample_images.append(self.process_image(self.file_paths[i]))\n",
    "            return sample_images\n",
    "\n",
    "        def load_imageset_from_file(self, path):\n",
    "            files = []\n",
    "            with open(path) as f:\n",
    "                for line in f:\n",
    "                    files.append(line.rstrip())\n",
    "            files = np.array(files)\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(files)\n",
    "            return files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Xception(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(256, activation='relu')(x)\n",
    "# and a dropout to prevent overfitting\n",
    "x = Dropout(0.2)(x) \n",
    "# and a logistic layer\n",
    "predictions = Dense(len(categories), activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  }
 ]
}